{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0aa12ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "import glob\n",
    "from dataclasses import dataclass\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_boats_trajectories = {}\n",
    "dataset_path = \"../../data/FishingKoreaAIS_sampled/*.csv\"\n",
    "dynamic_data_files = glob.glob(dataset_path)\n",
    "dynamic_data_files.sort(key=lambda data: int(data.split(\"len_\")[1].split(\"_mmsi_\")[0]), reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd590b80",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1ac2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AISColumnNames:\n",
    "    Date: str = \"Date\"\n",
    "    Sampled_Date: str = \"Sampled_Date\"\n",
    "    Latitude: str = \"Latitude\"\n",
    "    Longitude: str = \"Longitude\"\n",
    "    Pseudo_Longitude: str = \"Pseudo_Longitude\"\n",
    "    SOG: str = \"SOG\"\n",
    "    COG: str = \"COG\"\n",
    "    Heading: str = \"Heading\"\n",
    "\n",
    "    n_Latitude: str = \"norm Latitude\"\n",
    "    n_Longitude: str = \"norm Longitude\"\n",
    "    n_SOG: str = \"norm SOG\"\n",
    "    n_COG: str = \"norm COG\"\n",
    "    n_Heading: str = \"norm Heading\"\n",
    "\n",
    "    is_synthetic: str = \"is_synthetic\"\n",
    "    to_predict: str = \"to_predict\"\n",
    "\n",
    "cols: AISColumnNames = AISColumnNames()\n",
    "target_freq_in_minutes = 10\n",
    "target_freq: str = f\"{target_freq_in_minutes}min\"\n",
    "sample_T: pd.Timedelta = pd.Timedelta(minutes=target_freq_in_minutes)\n",
    "\n",
    "\n",
    "def get_trajectory_sequences(trajectory_sampled: pd.DataFrame, time_column_name=None\n",
    "    ) -> List[pd.DataFrame]:\n",
    "        if time_column_name is None:\n",
    "            time_column_name = cols.Sampled_Date\n",
    "        trajectory_sequences: List[pd.DataFrame] = []  # To store the sequences\n",
    "        current_sequence = pd.DataFrame(\n",
    "            columns=trajectory_sampled.columns\n",
    "        )  # DF To track the current sequence\n",
    "\n",
    "        # Iterate through the timestamps\n",
    "        for i in range(len(trajectory_sampled) - 1):\n",
    "            if (\n",
    "                trajectory_sampled[time_column_name][i + 1]\n",
    "                - trajectory_sampled[time_column_name][i]\n",
    "                == sample_T\n",
    "            ):\n",
    "                # If the difference is 10 minutes, add the current timestamp to the sequence\n",
    "                if len(current_sequence) == 0:\n",
    "                    current_sequence = trajectory_sampled.iloc[\n",
    "                        [i]\n",
    "                    ]  # Add the first timestamp of the sequence\n",
    "                current_sequence = pd.concat(\n",
    "                    [current_sequence, trajectory_sampled.iloc[[i + 1]]],\n",
    "                    ignore_index=True,\n",
    "                )  # Add the next timestamp\n",
    "            else:\n",
    "                # If the difference is not 10 minutes, end the current sequence\n",
    "                if len(current_sequence) != 0:\n",
    "                    trajectory_sequences.append(\n",
    "                        current_sequence\n",
    "                    )  # Store the completed sequence\n",
    "                    current_sequence = pd.DataFrame(\n",
    "                        columns=trajectory_sampled.columns\n",
    "                    )  # Reset the current sequence\n",
    "\n",
    "        # Handle the last sequence if it ends at the last timestamp\n",
    "        if len(current_sequence) != 0:\n",
    "            trajectory_sequences.append(current_sequence)\n",
    "\n",
    "        return trajectory_sequences\n",
    "    \n",
    "class AdaptiveExtendedKalmanFilter:\n",
    "    def __init__(self, initial_state, initial_covariance, process_noise, measurement_noise, alpha=0.7):\n",
    "        \"\"\"\n",
    "        Initialize the Adaptive Extended Kalman Filter.\n",
    "        \n",
    "        Parameters:\n",
    "        - initial_state: Initial state vector [lat, lon, sog, cog]\n",
    "        - initial_covariance: Initial covariance matrix\n",
    "        - process_noise: Process noise covariance matrix\n",
    "        - measurement_noise: Measurement noise covariance matrix\n",
    "        \"\"\"\n",
    "        self.state = initial_state\n",
    "        self.covariance = initial_covariance\n",
    "        self.Q = process_noise  # Process noise covariance\n",
    "        self.R = measurement_noise  # Measurement noise covariance\n",
    "        self.innovation_history = []\n",
    "        self.window_size = 5  # Window size for adaptive estimation\n",
    "        self.alpha = alpha  # Forgetting factor\n",
    "        \n",
    "    def predict(self, dt):\n",
    "        \"\"\"\n",
    "        Prediction step of the AEKF.\n",
    "        \n",
    "        Parameters:\n",
    "        - dt: Time step in hours (since coordinates are in degrees)\n",
    "        \"\"\"\n",
    "        # State transition matrix (simple constant velocity model)\n",
    "        F = np.eye(4)\n",
    "        F[0, 2] = dt * np.cos(np.radians(self.state[3])) / 60  # latitude change from SOG/COG\n",
    "        F[1, 2] = dt * np.sin(np.radians(self.state[3])) / 60  # longitude change from SOG/COG\n",
    "        \n",
    "        # Predict state\n",
    "        self.state = F @ self.state\n",
    "        \n",
    "        # Predict covariance\n",
    "        self.covariance = F @ self.covariance @ F.T + self.Q\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    def update(self, measurement):\n",
    "        \"\"\"\n",
    "        Update step of the AEKF with adaptive noise estimation.\n",
    "        \n",
    "        Parameters:\n",
    "        - measurement: [lat, lon, sog, cog]\n",
    "        \"\"\"\n",
    "        # Measurement matrix (we directly observe all states)\n",
    "        H = np.eye(4)\n",
    "        \n",
    "        # Calculate innovation\n",
    "        innovation = measurement - H @ self.state\n",
    "        self.innovation_history.append(innovation)\n",
    "        \n",
    "        # Keep only the most recent innovations\n",
    "        if len(self.innovation_history) > self.window_size:\n",
    "            self.innovation_history.pop(0)\n",
    "        \n",
    "        # Adaptive estimation of measurement noise\n",
    "        if len(self.innovation_history) >= 2:\n",
    "            innovation_cov = np.cov(np.array(self.innovation_history).T)\n",
    "            self.R = self.alpha * innovation_cov + (1 - self.alpha) * self.R\n",
    "        \n",
    "        # Kalman gain\n",
    "        S = H @ self.covariance @ H.T + self.R\n",
    "        K = self.covariance @ H.T @ inv(S)\n",
    "        \n",
    "        # Update state\n",
    "        self.state = self.state + K @ innovation\n",
    "        \n",
    "        # Update covariance\n",
    "        self.covariance = (np.eye(4) - K @ H) @ self.covariance\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    def get_state(self):\n",
    "        \"\"\"Return the current state estimate.\"\"\"\n",
    "        return self.state\n",
    "\n",
    "\n",
    "def AEKF_traj(df, alpha = 0.7):\n",
    "    \"\"\"\n",
    "    Apply Adaptive Extended Kalman Filter to the vessel tracking dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame with columns ['Sampled_Date', 'MMSI', 'Latitude', 'Longitude', 'SOG', 'COG', 'Heading']\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with filtered positions and additional AEKF output\n",
    "    \"\"\"\n",
    "    # Sort by MMSI and timestamp\n",
    "    df = df.sort_values(['MMSI', 'Sampled_Date'])\n",
    "    \n",
    "    # Convert datetime to seconds for delta time calculation\n",
    "    df['time_seconds'] = pd.to_datetime(df['Sampled_Date']).astype('int64') // 10**9\n",
    "    \n",
    "    # Initialize output columns\n",
    "    df['filtered_lat'] = np.nan\n",
    "    df['filtered_lon'] = np.nan\n",
    "    df['filtered_sog'] = np.nan\n",
    "    df['filtered_cog'] = np.nan\n",
    "    \n",
    "    # Group by vessel (MMSI)\n",
    "    for mmsi, group in df.groupby('MMSI'):\n",
    "        if len(group) < 2:\n",
    "            continue  # Need at least 2 points for filtering\n",
    "            \n",
    "        # Initialize AEKF with first measurement\n",
    "        initial_state = np.array([\n",
    "            group.iloc[0]['Latitude'],\n",
    "            group.iloc[0]['Longitude'],\n",
    "            group.iloc[0]['SOG'],\n",
    "            group.iloc[0]['COG']\n",
    "        ])\n",
    "        \n",
    "        # Initial covariance (tune these based on your application)\n",
    "        initial_covariance =  np.diag([1e-4, 1e-4, 0.1, 1.0])\n",
    "        \n",
    "        # Process noise covariance (tune these)\n",
    "        process_noise = np.diag([1e-6, 1e-6, 0.01, 0.1]) \n",
    "        \n",
    "        # Measurement noise covariance (tune these)\n",
    "        measurement_noise = np.diag([1e-5, 1e-5, 0.1, 1.0]) \n",
    "        \n",
    "        aekf = AdaptiveExtendedKalmanFilter(\n",
    "            initial_state, initial_covariance, process_noise, measurement_noise, alpha\n",
    "        )\n",
    "        \n",
    "        # Store first filtered values (same as measurement)\n",
    "        # df.loc[group.index[0], 'filtered_lat'] = initial_state[0]\n",
    "        # df.loc[group.index[0], 'filtered_lon'] = initial_state[1]\n",
    "        # df.loc[group.index[0], 'filtered_sog'] = initial_state[2]\n",
    "        # df.loc[group.index[0], 'filtered_cog'] = initial_state[3]\n",
    "        \n",
    "        # Iterate through remaining points\n",
    "        for i in range(1, len(group)):\n",
    "            prev_time = group.iloc[i-1]['time_seconds']\n",
    "            curr_time = group.iloc[i]['time_seconds']\n",
    "            dt = (curr_time - prev_time) / 3600  # hours\n",
    "            \n",
    "            # Prediction step\n",
    "            aekf.predict(dt)\n",
    "            \n",
    "            # Update step with current measurement\n",
    "            measurement = np.array([\n",
    "                group.iloc[i]['Latitude'],\n",
    "                group.iloc[i]['Longitude'],\n",
    "                group.iloc[i]['SOG'],\n",
    "                group.iloc[i]['COG']\n",
    "            ])\n",
    "            \n",
    "            filtered_state = aekf.update(measurement)\n",
    "            \n",
    "            # Store filtered values\n",
    "            df.loc[group.index[i], cols.Latitude] = filtered_state[0]\n",
    "            df.loc[group.index[i], cols.Longitude] = filtered_state[1]\n",
    "            df.loc[group.index[i], cols.SOG] = filtered_state[2]\n",
    "            df.loc[group.index[i], cols.COG] = filtered_state[3]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def restore_missing_timestamps(df, freq='10T', interpolation_method='linear', noise_level=0.0):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Make sure the time column is in datetime format\n",
    "    df[cols.Sampled_Date] = pd.to_datetime(df[cols.Sampled_Date])\n",
    "    \n",
    "    # Set the timestamp as index\n",
    "    df = df.set_index(cols.Sampled_Date)\n",
    "\n",
    "    full_range = pd.date_range(\n",
    "        start=df.index.min(),\n",
    "        end=df.index.max(),\n",
    "        freq=freq\n",
    "    )\n",
    "        \n",
    "    # Reindex to the complete time range\n",
    "    df = df.reindex(full_range)\n",
    "        \n",
    "    # Reset index to make Sampled_Date a column again\n",
    "    df = df.reset_index().rename(columns={'index': cols.Sampled_Date})\n",
    "            \n",
    "    # Interpolate numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Store original non-null values to only add noise to interpolated points\n",
    "    original_mask = df[numeric_cols].notna()\n",
    "    \n",
    "    # Perform interpolation\n",
    "    df[numeric_cols] = df[numeric_cols].interpolate(method=interpolation_method)\n",
    "    \n",
    "    # Add noise (either independent or random walk)\n",
    "    if noise_level > 0:\n",
    "        # Apply random walk noise between known points\n",
    "        for col in [cols.Longitude, cols.Latitude]:\n",
    "            # Find where original data exists (anchor points)\n",
    "            anchors = original_mask[col]\n",
    "            anchor_indices = np.where(anchors)[0]\n",
    "            \n",
    "            # Iterate through each segment between anchors\n",
    "            for i in range(len(anchor_indices) - 1):\n",
    "                start_idx = anchor_indices[i]\n",
    "                end_idx = anchor_indices[i + 1]\n",
    "                segment_length = end_idx - start_idx - 1\n",
    "                \n",
    "                if segment_length > 0:\n",
    "                    # Generate random steps (Brownian motion)\n",
    "                    steps = np.random.normal(\n",
    "                        scale=noise_level, \n",
    "                        size=segment_length\n",
    "                    )\n",
    "                    # Accumulate noise (cumulative sum)\n",
    "                    noise = np.cumsum(steps)\n",
    "                    # Apply noise to the interpolated segment\n",
    "                    df.loc[start_idx + 1 : end_idx - 1, col] += noise\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = restore_missing_timestamps(your_dataframe)\n",
    "# Example usage:\n",
    "# df = pd.read_csv('your_data.csv')  # Load your data\n",
    "# filtered_df = apply_aekf_to_dataframe(df)\n",
    "\n",
    "\n",
    "def plot_plotly_trajectory(dfs: List[pd.DataFrame], \n",
    "                                   color_sequence=None,\n",
    "                                   line_width=2,\n",
    "                                   marker_size=4):\n",
    "    if not dfs:\n",
    "        raise ValueError(\"Empty list of DataFrames provided\")\n",
    "    \n",
    "    # Combine all segments with a segment ID\n",
    "    combined_df = pd.concat(\n",
    "        [df.assign(segment_id=i) for i, df in enumerate(dfs)],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "    if color_sequence is None:\n",
    "        color_sequence = px.colors.qualitative.Plotly\n",
    "    \n",
    "    fig = px.line_mapbox(\n",
    "        combined_df,\n",
    "        lat=\"Latitude\",\n",
    "        lon=\"Longitude\",\n",
    "        color=\"segment_id\",\n",
    "        color_discrete_sequence=[\"blue\"],\n",
    "        hover_name=\"Sampled_Date\",\n",
    "        hover_data=[\"SOG\", \"COG\", \"MMSI\"],\n",
    "        zoom=10,\n",
    "        height=600,\n",
    "        title=\"Vessel Trajectory Segments\"\n",
    "    )\n",
    "    \n",
    "    # Update marker appearance\n",
    "    fig.update_traces(\n",
    "        mode=\"lines+markers\",\n",
    "        line=dict(width=line_width),\n",
    "        marker=dict(size=marker_size)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0},\n",
    "        showlegend=False,\n",
    "        legend_title_text=\"Trajectory Segment\"\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_plotly_trajectory_groups(df_groups: List[List[pd.DataFrame]],\n",
    "                         group_names, \n",
    "                         color_sequence=None,\n",
    "                         line_width=2,\n",
    "                         marker_size=4):\n",
    "    if not df_groups:\n",
    "        raise ValueError(\"Empty list of DataFrame groups provided\")\n",
    "    \n",
    "    if color_sequence is None:\n",
    "        color_sequence = px.colors.qualitative.Plotly\n",
    "    \n",
    "    # Create empty figure with proper mapbox setup\n",
    "    fig = px.scatter_mapbox(lat=[None], lon=[None]).update_layout(\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        mapbox_zoom=8,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    for group_id, df_group in enumerate(df_groups):\n",
    "        group_color = color_sequence[group_id % len(color_sequence)]\n",
    "        \n",
    "        for segment_id, df in enumerate(df_group):\n",
    "            if len(df) == 0:\n",
    "                continue  # Skip empty dataframes\n",
    "                \n",
    "            # Add line trace for this segment\n",
    "            fig.add_trace(\n",
    "                px.line_mapbox(\n",
    "                    df,\n",
    "                    lat=\"Latitude\",\n",
    "                    lon=\"Longitude\",\n",
    "                    color_discrete_sequence=[group_color]\n",
    "                ).data[0].update(\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(width=line_width),\n",
    "                    marker=dict(size=marker_size),\n",
    "                    name=f\"{group_names[group_id]}\",\n",
    "                    showlegend=(segment_id == 0),  # Only show legend for first segment\n",
    "                    legendgroup=f\"{group_names[group_id]}\",\n",
    "                    hoverinfo=\"text\",\n",
    "                    customdata=df[[\"Sampled_Date\", \"SOG\", \"COG\", \"MMSI\"]],\n",
    "                    hovertemplate=(\n",
    "                        \"Latitude: %{lat}<br>\"\n",
    "                        \"Longitude: %{lon}<br>\"\n",
    "                        \"Date: %{customdata[0]}<br>\"\n",
    "                        \"SOG: %{customdata[1]}<br>\"\n",
    "                        \"COG: %{customdata[2]}<br>\"\n",
    "                        \"MMSI: %{customdata[3]}<extra></extra>\"\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0},\n",
    "        showlegend=True,\n",
    "        legend_title_text=\"Trajectory Groups\",\n",
    "        title=\"Vessel Trajectory\"\n",
    "    )\n",
    "    \n",
    "    # Auto-zoom to the data\n",
    "    if len(df_groups) > 0 and len(df_groups[0]) > 0:\n",
    "        first_df = df_groups[0][0]\n",
    "        fig.update_mapboxes(\n",
    "            center=dict(\n",
    "                lat=first_df[\"Latitude\"].mean(),\n",
    "                lon=first_df[\"Longitude\"].mean()\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef981ff",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0393819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4454"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(dynamic_data_files[0].split(\"len_\")[1].split(\"_mmsi_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sampled_data_file in dynamic_data_files:\n",
    "    if int(sampled_data_file.split(\"len_\")[1].split(\"_mmsi_\")[0]) > 2096:\n",
    "        continue\n",
    "    if int(sampled_data_file.split(\"len_\")[1].split(\"_mmsi_\")[0]) < 2000:\n",
    "        break\n",
    "    sample_traj = pd.read_csv(sampled_data_file, index_col=0)\n",
    "    sample_traj['Sampled_Date'] = pd.to_datetime(sample_traj['Sampled_Date'])\n",
    "    # sample_traj\n",
    "    sample_traj_sequences = get_trajectory_sequences(sample_traj)\n",
    "    fig = plot_plotly_trajectory_groups([sample_traj_sequences], group_names=[\"Initial trajectory\"])\n",
    "    fig.write_image(f\"results/png_{int(sample_traj[\"MMSI\"][0])}.png\")\n",
    "    fig.write_html(f\"results/html_{int(sample_traj[\"MMSI\"][0])}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6a29033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1991'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data_file.split(\"len_\")[1].split(\"_mmsi_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e76ed56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_44455/3677791823.py:238: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.89\n",
    "sample_traj_sequences = get_trajectory_sequences(sample_traj)\n",
    "### JUST AEKF\n",
    "interpolated_sample_traj = restore_missing_timestamps(sample_traj, noise_level=0.0000)\n",
    "interpolated_sample_traj_sequences = get_trajectory_sequences(interpolated_sample_traj)\n",
    "AEKF_interpolated_sample_traj= AEKF_traj(interpolated_sample_traj, alpha)\n",
    "AEKF_interpolated_sample_traj_sequences = get_trajectory_sequences(AEKF_interpolated_sample_traj)\n",
    "\n",
    "fig = plot_plotly_trajectory_groups([AEKF_interpolated_sample_traj_sequences, sample_traj_sequences], group_names=[\"Interpolated + AEKF\", \"Initial trajectory\"])\n",
    "fig.write_image(f\"results/png_{int(sample_traj[\"MMSI\"][0])}_interpolated_traj_alpha_{alpha}.png\")\n",
    "fig.write_html(f\"results/html_{int(sample_traj[\"MMSI\"][0])}_interpolated_traj_alpha_{alpha}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6a6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
