{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f578c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "import geoviews as gv\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "\n",
    "# -------------------------------------\n",
    "# Database Configuration (Postgres)\n",
    "# -------------------------------------\n",
    "db_config = {\n",
    "    \"host\": \"143.248.230.55\",\n",
    "    \"port\": \"5432\",\n",
    "    \"dbname\": \"AIS_DB_Prototype\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"password\",\n",
    "}\n",
    "\n",
    "# Build SQLAlchemy engine\n",
    "database_url = (\n",
    "    f\"postgresql://{db_config['user']}:{db_config['password']}\"\n",
    "    f\"@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\"\n",
    ")\n",
    "engine = create_engine(database_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d3f23b",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bde99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fishing_vessels_voyages_with_loitering(sample_n: int = 5) -> pd.DataFrame:\n",
    "\n",
    "    sql = text(\n",
    "        \"\"\"\n",
    "        SELECT\n",
    "            mmsi,\n",
    "            CAST(eta AS TIMESTAMP)\n",
    "            AS eta_time,\n",
    "            COUNT(*)\n",
    "            AS entry_count\n",
    "            FROM public.loitering_new_v2\n",
    "            GROUP BY\n",
    "            mmsi,\n",
    "            CAST(eta AS TIMESTAMP)\n",
    "            HAVING\n",
    "            COUNT(*) > 10\n",
    "            ORDER BY\n",
    "            entry_count,\n",
    "            mmsi,\n",
    "            eta_time\n",
    "        LIMIT :n;\n",
    "    \"\"\"\n",
    "    )\n",
    "    return pd.read_sql(sql, engine, params={\"n\": sample_n}, parse_dates=[\"eta_time\"])\n",
    "\n",
    "def load_loitering_part_of_trajectory(mmsi: int, eta_time: pd.Timestamp) -> pd.DataFrame:\n",
    "    sql = text(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            posutc AS ts_string,\n",
    "            latitude,\n",
    "            longitude,\n",
    "            sog,\n",
    "            cog,\n",
    "            heading\n",
    "        FROM public.loitering_new_v2\n",
    "        WHERE mmsi = :m\n",
    "          AND CAST(eta AS TIMESTAMP) = :e\n",
    "        ORDER BY posutc::timestamp;\n",
    "    \"\"\"\n",
    "    )\n",
    "    df = pd.read_sql(sql, engine, params={\"m\": mmsi, \"e\": eta_time})\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"ts_string\"], errors=\"coerce\")\n",
    "\n",
    "    # Convert columns to numeric, coercing invalid values to NaN\n",
    "    numeric_columns = [\"latitude\", \"longitude\", \"sog\", \"cog\", \"heading\"]\n",
    "    for col in numeric_columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    df.drop(columns=[\"ts_string\"], inplace=True)\n",
    "    # Drop rows where any of the specified columns or timestamp is NaN\n",
    "    return df.dropna(subset=[\"timestamp\"] + numeric_columns)\n",
    "\n",
    "def load_full_trajectory(mmsi: int, eta_time: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ALL AIS points (posutc, latitude, longitude, sog, cog, heading)\n",
    "    for a given (mmsi, eta) from ais_korea.\n",
    "    Returns a DataFrame with parsed timestamps.\n",
    "    \"\"\"\n",
    "    sql = text(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            posutc AS ts_string,\n",
    "            latitude,\n",
    "            longitude,\n",
    "            sog,\n",
    "            cog,\n",
    "            heading\n",
    "        FROM public.ais_korea\n",
    "        WHERE mmsi = :m\n",
    "          AND CAST(eta AS TIMESTAMP) = :e\n",
    "        ORDER BY posutc::timestamp;\n",
    "    \"\"\"\n",
    "    )\n",
    "    df = pd.read_sql(sql, engine, params={\"m\": mmsi, \"e\": eta_time})\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"ts_string\"], errors=\"coerce\")\n",
    "\n",
    "    # Convert columns to numeric, coercing invalid values to NaN\n",
    "    numeric_columns = [\"latitude\", \"longitude\", \"sog\", \"cog\", \"heading\"]\n",
    "    for col in numeric_columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    df.drop(columns=[\"ts_string\"], inplace=True)\n",
    "    # Drop rows where any of the specified columns or timestamp is NaN\n",
    "    return df.dropna(subset=[\"timestamp\"] + numeric_columns)\n",
    "\n",
    "\n",
    "# latitude\tlongitude\tsog\tcog\theading\ttimestamp\n",
    "@dataclass\n",
    "class AISColumnNames:\n",
    "    # Date: str = \"Date\"\n",
    "    # Sampled_Date: str = \"Sampled_Date\"\n",
    "    # Latitude: str = \"Latitude\"\n",
    "    # Longitude: str = \"Longitude\"\n",
    "    # Pseudo_Longitude: str = \"Pseudo_Longitude\"\n",
    "    # SOG: str = \"SOG\"\n",
    "    # COG: str = \"COG\"\n",
    "    # Heading: str = \"Heading\"\n",
    "\n",
    "    # n_Latitude: str = \"norm Latitude\"\n",
    "    # n_Longitude: str = \"norm Longitude\"\n",
    "    # n_SOG: str = \"norm SOG\"\n",
    "    # n_COG: str = \"norm COG\"\n",
    "    # n_Heading: str = \"norm Heading\"\n",
    "    Date: str = \"timestamp\"\n",
    "    Sampled_Date: str = \"sampled_timestamp\"\n",
    "    Latitude: str = \"latitude\"\n",
    "    Longitude: str = \"longitude\"\n",
    "    Pseudo_Longitude: str = \"pseudo_longitude\"\n",
    "    SOG: str = \"sog\"\n",
    "    COG: str = \"cog\"\n",
    "    Heading: str = \"heading\"\n",
    "\n",
    "    n_Latitude: str = \"norm_latitude\"\n",
    "    n_Longitude: str = \"norm_longitude\"\n",
    "    n_SOG: str = \"norm_sog\"\n",
    "    n_COG: str = \"norm_cog\"\n",
    "    n_Heading: str = \"norm_heading\"\n",
    "\n",
    "    is_synthetic: str = \"is_synthetic\"\n",
    "    to_predict: str = \"to_predict\"\n",
    "\n",
    "\n",
    "cols: AISColumnNames = AISColumnNames()\n",
    "target_freq_in_minutes = 10\n",
    "target_freq: str = f\"{target_freq_in_minutes}min\"\n",
    "sample_T: pd.Timedelta = pd.Timedelta(minutes=target_freq_in_minutes)\n",
    "\n",
    "\n",
    "def get_sampled_trajectory(trajectory: pd.DataFrame) -> pd.DataFrame:\n",
    "    trajectory[cols.Date] = pd.to_datetime(trajectory[cols.Date])\n",
    "    trajectory = trajectory.set_index(cols.Date)\n",
    "    trajectory = trajectory.sort_index()\n",
    "\n",
    "    # add first and last steps of trajectory which are divisible by 10 minutes\n",
    "    first = trajectory.iloc[:1].copy()\n",
    "    first.index = [trajectory.index.min().floor(target_freq)]\n",
    "    last = trajectory.iloc[-1:].copy()\n",
    "    last.index = [trajectory.index.max().ceil(target_freq)]\n",
    "    trajectory = pd.concat([first, trajectory, last])\n",
    "\n",
    "    # Define exact 10-minute sampling times\n",
    "    start_time = trajectory.index.min().floor(\"h\")  # Round down to the nearest hour\n",
    "    end_time = trajectory.index.max().ceil(\"h\")  # Round up to the nearest hour\n",
    "    sampling_times = pd.date_range(start_time, end_time, freq=target_freq)\n",
    "\n",
    "    # Filter only timestamps where at least one real record exists within Â±10 minutes\n",
    "    valid_sampling_times = [\n",
    "        t for t in sampling_times if any(abs(trajectory.index - t) <= sample_T)\n",
    "    ]\n",
    "\n",
    "    trajectory = trajectory[~trajectory.index.duplicated(keep=\"first\")]\n",
    "    trajectory_interpolated = trajectory.reindex(\n",
    "        trajectory.index.union(valid_sampling_times)\n",
    "    ).sort_index()\n",
    "\n",
    "    # Perform linear interpolation\n",
    "    trajectory_interpolated = trajectory_interpolated.interpolate(method=\"time\")\n",
    "\n",
    "    # Keep only the sampled timestamps and drop any remaining NaNs\n",
    "    trajectory_sampled = (\n",
    "        trajectory_interpolated.loc[valid_sampling_times].dropna().reset_index()\n",
    "    )\n",
    "    trajectory_sampled.rename(columns={\"index\": cols.Sampled_Date}, inplace=True)\n",
    "    return trajectory_sampled\n",
    "\n",
    "\n",
    "def get_trajectory_sequences(\n",
    "    trajectory_sampled: pd.DataFrame, time_column_name=None\n",
    ") -> List[pd.DataFrame]:\n",
    "    if time_column_name is None:\n",
    "        time_column_name = cols.Sampled_Date\n",
    "    trajectory_sequences: List[pd.DataFrame] = []  # To store the sequences\n",
    "    current_sequence = pd.DataFrame(\n",
    "        columns=trajectory_sampled.columns\n",
    "    )  # DF To track the current sequence\n",
    "\n",
    "    # Iterate through the timestamps\n",
    "    for i in range(len(trajectory_sampled) - 1):\n",
    "        if (\n",
    "            trajectory_sampled[time_column_name][i + 1]\n",
    "            - trajectory_sampled[time_column_name][i]\n",
    "            == sample_T\n",
    "        ):\n",
    "            # If the difference is 10 minutes, add the current timestamp to the sequence\n",
    "            if len(current_sequence) == 0:\n",
    "                current_sequence = trajectory_sampled.iloc[\n",
    "                    [i]\n",
    "                ]  # Add the first timestamp of the sequence\n",
    "            current_sequence = pd.concat(\n",
    "                [current_sequence, trajectory_sampled.iloc[[i + 1]]],\n",
    "                ignore_index=True,\n",
    "            )  # Add the next timestamp\n",
    "        else:\n",
    "            # If the difference is not 10 minutes, end the current sequence\n",
    "            if len(current_sequence) != 0:\n",
    "                trajectory_sequences.append(\n",
    "                    current_sequence\n",
    "                )  # Store the completed sequence\n",
    "                current_sequence = pd.DataFrame(\n",
    "                    columns=trajectory_sampled.columns\n",
    "                )  # Reset the current sequence\n",
    "\n",
    "    # Handle the last sequence if it ends at the last timestamp\n",
    "    if len(current_sequence) != 0:\n",
    "        trajectory_sequences.append(current_sequence)\n",
    "\n",
    "    return trajectory_sequences\n",
    "\n",
    "\n",
    "def plot_plotly_trajectory_groups(\n",
    "    df_groups: List[List[pd.DataFrame]],\n",
    "    group_names,\n",
    "    color_sequence=None,\n",
    "    line_width=2,\n",
    "    marker_size=4,\n",
    "):\n",
    "    if not df_groups:\n",
    "        raise ValueError(\"Empty list of DataFrame groups provided\")\n",
    "\n",
    "    if color_sequence is None:\n",
    "        color_sequence = px.colors.qualitative.Plotly\n",
    "\n",
    "    # Create empty figure with proper mapbox setup\n",
    "    fig = px.scatter_mapbox(lat=[None], lon=[None]).update_layout(\n",
    "        mapbox_style=\"open-street-map\", mapbox_zoom=8, height=600\n",
    "    )\n",
    "    min_lat = 360\n",
    "    max_lat = 0\n",
    "    min_lon = 360\n",
    "    max_lon = 0\n",
    "    for group_id, df_group in enumerate(df_groups):\n",
    "        group_color = color_sequence[group_id % len(color_sequence)]\n",
    "\n",
    "        for segment_id, df in enumerate(df_group):\n",
    "            if len(df) == 0:\n",
    "                continue  # Skip empty dataframes\n",
    "\n",
    "            # Add line trace for this segment\n",
    "            fig.add_trace(\n",
    "                px.line_mapbox(\n",
    "                    df,\n",
    "                    lat=cols.Latitude,\n",
    "                    lon=cols.Longitude,\n",
    "                    color_discrete_sequence=[group_color],\n",
    "                )\n",
    "                .data[0]\n",
    "                .update(\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(width=line_width),\n",
    "                    marker=dict(size=marker_size),\n",
    "                    name=f\"{group_names[group_id]}\",\n",
    "                    showlegend=(segment_id == 0),  # Only show legend for first segment\n",
    "                    legendgroup=f\"{group_names[group_id]}\",\n",
    "                    hoverinfo=\"text\",\n",
    "                    customdata=df[[cols.Sampled_Date, cols.SOG, cols.COG]],\n",
    "                    hovertemplate=(\n",
    "                        \"Latitude: %{lat}<br>\"\n",
    "                        \"Longitude: %{lon}<br>\"\n",
    "                        \"Date: %{customdata[0]}<br>\"\n",
    "                        \"SOG: %{customdata[1]}<br>\"\n",
    "                        \"COG: %{customdata[2]}<br>\"\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # min/max lat/lot\n",
    "            min_lat = min(min_lat, df[cols.Latitude].min())\n",
    "            max_lat = max(max_lat, df[cols.Latitude].max())\n",
    "            min_lon = min(min_lon, df[cols.Longitude].min())\n",
    "            max_lon = max(max_lon, df[cols.Longitude].max())\n",
    "\n",
    "    fig.update_layout(\n",
    "        margin={\"r\": 0, \"t\": 40, \"l\": 0, \"b\": 0},\n",
    "        showlegend=True,\n",
    "        legend_title_text=\"Trajectory Groups\",\n",
    "        title=\"Vessel Trajectory\",\n",
    "    )\n",
    "\n",
    "    # Auto-zoom to the data\n",
    "    if len(df_groups) > 0 and len(df_groups[0]) > 0:\n",
    "        fig.update_mapboxes(\n",
    "            center=dict(lat=(min_lat + max_lat) / 2, lon=(min_lon + max_lon) / 2)\n",
    "        )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e873b",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b399130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmsi</th>\n",
       "      <th>eta_time</th>\n",
       "      <th>entry_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36968098</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100900256</td>\n",
       "      <td>2023-12-10 12:00:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310696000</td>\n",
       "      <td>2023-11-20 06:00:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mmsi            eta_time  entry_count\n",
       "0   36968098 2023-01-01 00:00:00           11\n",
       "1  100900256 2023-12-10 12:00:00           11\n",
       "2  310696000 2023-11-20 06:00:00           11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voyages_df = load_fishing_vessels_voyages_with_loitering(sample_n=3)\n",
    "voyages_df  # display the sample selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a259e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mmsi                      36968098\n",
      "eta_time       2023-01-01 00:00:00\n",
      "entry_count                     11\n",
      "Name: 0, dtype: object\n",
      "1 mmsi                     100900256\n",
      "eta_time       2023-12-10 12:00:00\n",
      "entry_count                     11\n",
      "Name: 1, dtype: object\n",
      "2 mmsi                     310696000\n",
      "eta_time       2023-11-20 06:00:00\n",
      "entry_count                     11\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# voyages_df = load_fishing_vessels_voyages(sample_n=100)\n",
    "# voyages_df  # display the sample selection\n",
    "\n",
    "for idx, row in voyages_df.iterrows():\n",
    "    print(idx, row)\n",
    "    try:\n",
    "        m       = int(row[\"mmsi\"])\n",
    "        eta_val = row[\"eta_time\"]\n",
    "        \n",
    "        # Load full trajectory points\n",
    "        df = load_full_trajectory(m, eta_val)\n",
    "        sampled_boat_trajectory = get_sampled_trajectory(df)\n",
    "        # print(sampled_boat_trajectory)\n",
    "        sampled_boat_trajectory.to_csv(f\"../../data/loitering_sampled/len_{len(sampled_boat_trajectory)}_mmsi_{m}_eta_val_{eta_val}.csv\")\n",
    "        sample_traj_sequences = get_trajectory_sequences(sampled_boat_trajectory)\n",
    "        fig = plot_plotly_trajectory_groups([sample_traj_sequences], group_names=[\"Initial trajectory\"])\n",
    "        fig.write_image(f\"../../results/loitering_sampled/png_len_{len(sampled_boat_trajectory)}_mmsi_{m}_eta_val_{eta_val}.png\")\n",
    "        fig.write_html(f\"../../results/loitering_sampled/html_len_{len(sampled_boat_trajectory)}_mmsi_{m}_eta_val_{eta_val}.html\")\n",
    "        \n",
    "        \n",
    "        df_loitering = load_loitering_part_of_trajectory(m, eta_val)\n",
    "        sampled_boat_trajectory_loitering = get_sampled_trajectory(df_loitering)\n",
    "        # print(sampled_boat_trajectory)\n",
    "        # print(sampled_boat_trajectory)\n",
    "        sampled_boat_trajectory_loitering.to_csv(f\"../../data/loitering_sampled/len_{len(sampled_boat_trajectory_loitering)}_mmsi_{m}_eta_val_{eta_val}_loitering.csv\")\n",
    "        sample_traj_sequences_loitering = get_trajectory_sequences(sampled_boat_trajectory_loitering)\n",
    "        fig = plot_plotly_trajectory_groups([sample_traj_sequences_loitering], group_names=[\"Initial trajectory\"])\n",
    "        fig.write_image(f\"../../results/loitering_sampled/png_len_{len(sampled_boat_trajectory_loitering)}_mmsi_{m}_eta_val_{eta_val}_loitering.png\")\n",
    "        fig.write_html(f\"../../results/loitering_sampled/html_len_{len(sampled_boat_trajectory_loitering)}_mmsi_{m}_eta_val_{eta_val}_loitering.html\")\n",
    "    except Exception as e:\n",
    "        print(f\"Couldn't process {row}: e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c7f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
