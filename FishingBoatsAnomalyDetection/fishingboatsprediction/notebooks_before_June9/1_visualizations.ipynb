{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa83fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "import glob\n",
    "from dataclasses import dataclass\n",
    "import folium\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import pydeck as pdk\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b91e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../../data/FishingKoreaAIS/Dynamic_20230502_fishing_boats.csv...\n",
      "Done!\n",
      "Reading ../../data/FishingKoreaAIS/Dynamic_20230501_fishing_boats.csv...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "all_boats_trajectories = {}\n",
    "dataset_path = \"../../data/FishingKoreaAIS/Dynamic_*.csv\"\n",
    "dynamic_data_files = glob.glob(dataset_path)\n",
    "\n",
    "for dynamic_data_file in dynamic_data_files:\n",
    "    print(f\"Reading {dynamic_data_file}...\")\n",
    "    df_dynamic = pd.read_csv(dynamic_data_file)\n",
    "    data_grouped = df_dynamic.groupby(\"MMSI\")\n",
    "    for mmsi, data in data_grouped:\n",
    "        if mmsi not in all_boats_trajectories:\n",
    "            all_boats_trajectories[mmsi] = (\n",
    "                data.copy()\n",
    "            )  # Create a copy to avoid SettingWithCopyWarning\n",
    "        else:\n",
    "            all_boats_trajectories[mmsi] = pd.concat(\n",
    "                [all_boats_trajectories[mmsi], data], ignore_index=True\n",
    "            )\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "782c8bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_boats_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48830684",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AISColumnNames:\n",
    "    Date: str = \"Date\"\n",
    "    Sampled_Date: str = \"Sampled_Date\"\n",
    "    Latitude: str = \"Latitude\"\n",
    "    Longitude: str = \"Longitude\"\n",
    "    Pseudo_Longitude: str = \"Pseudo_Longitude\"\n",
    "    SOG: str = \"SOG\"\n",
    "    COG: str = \"COG\"\n",
    "    Heading: str = \"Heading\"\n",
    "\n",
    "    n_Latitude: str = \"norm Latitude\"\n",
    "    n_Longitude: str = \"norm Longitude\"\n",
    "    n_SOG: str = \"norm SOG\"\n",
    "    n_COG: str = \"norm COG\"\n",
    "    n_Heading: str = \"norm Heading\"\n",
    "\n",
    "    is_synthetic: str = \"is_synthetic\"\n",
    "    to_predict: str = \"to_predict\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0e413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols: AISColumnNames = AISColumnNames()\n",
    "target_freq_in_minutes = 10\n",
    "target_freq: str = f\"{target_freq_in_minutes}min\"\n",
    "sample_T: pd.Timedelta = pd.Timedelta(minutes=target_freq_in_minutes)\n",
    "\n",
    "def get_sampled_trajectory(trajectory: pd.DataFrame) -> pd.DataFrame:\n",
    "        trajectory[cols.Date] = pd.to_datetime(trajectory[cols.Date])\n",
    "        trajectory = trajectory.set_index(cols.Date)\n",
    "        trajectory = trajectory.sort_index()\n",
    "\n",
    "        # add first and last steps of trajectory which are divisible by 10 minutes\n",
    "        first = trajectory.iloc[:1].copy()\n",
    "        first.index = [trajectory.index.min().floor(target_freq)]\n",
    "        last = trajectory.iloc[-1:].copy()\n",
    "        last.index = [trajectory.index.max().ceil(target_freq)]\n",
    "        trajectory = pd.concat([first, trajectory, last])\n",
    "\n",
    "        # Define exact 10-minute sampling times\n",
    "        start_time = trajectory.index.min().floor(\"h\")  # Round down to the nearest hour\n",
    "        end_time = trajectory.index.max().ceil(\"h\")  # Round up to the nearest hour\n",
    "        sampling_times = pd.date_range(start_time, end_time, freq=target_freq)\n",
    "\n",
    "        # Filter only timestamps where at least one real record exists within Â±10 minutes\n",
    "        valid_sampling_times = [\n",
    "            t\n",
    "            for t in sampling_times\n",
    "            if any(abs(trajectory.index - t) <= sample_T)\n",
    "        ]\n",
    "\n",
    "        trajectory = trajectory[~trajectory.index.duplicated(keep=\"first\")]\n",
    "        trajectory_interpolated = trajectory.reindex(\n",
    "            trajectory.index.union(valid_sampling_times)\n",
    "        ).sort_index()\n",
    "\n",
    "        # Perform linear interpolation\n",
    "        trajectory_interpolated = trajectory_interpolated.interpolate(method=\"time\")\n",
    "\n",
    "        # Keep only the sampled timestamps and drop any remaining NaNs\n",
    "        trajectory_sampled = (\n",
    "            trajectory_interpolated.loc[valid_sampling_times].dropna().reset_index()\n",
    "        )\n",
    "        trajectory_sampled.rename(\n",
    "            columns={\"index\": cols.Sampled_Date}, inplace=True\n",
    "        )\n",
    "        return trajectory_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0df6b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMSI</th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>SOG</th>\n",
       "      <th>COG</th>\n",
       "      <th>Heading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41215086</td>\n",
       "      <td>2023-05-02 01:31:43</td>\n",
       "      <td>36.729807</td>\n",
       "      <td>123.20306</td>\n",
       "      <td>1.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41215086</td>\n",
       "      <td>2023-05-01 22:53:52</td>\n",
       "      <td>36.700318</td>\n",
       "      <td>123.18686</td>\n",
       "      <td>4.8</td>\n",
       "      <td>274.9</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MMSI                 Date   Latitude  Longitude  SOG    COG  Heading\n",
       "0  41215086  2023-05-02 01:31:43  36.729807  123.20306  1.1   32.1       32\n",
       "1  41215086  2023-05-01 22:53:52  36.700318  123.18686  4.8  274.9      274"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_boats_trajectories.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a77f65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_traj = get_sampled_trajectory(list(all_boats_trajectories.values())[1])\n",
    "# sample_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab69f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory_sequences(trajectory_sampled: pd.DataFrame, time_column_name=None\n",
    "    ) -> List[pd.DataFrame]:\n",
    "        if time_column_name is None:\n",
    "            time_column_name = cols.Sampled_Date\n",
    "        trajectory_sequences: List[pd.DataFrame] = []  # To store the sequences\n",
    "        current_sequence = pd.DataFrame(\n",
    "            columns=trajectory_sampled.columns\n",
    "        )  # DF To track the current sequence\n",
    "\n",
    "        # Iterate through the timestamps\n",
    "        for i in range(len(trajectory_sampled) - 1):\n",
    "            if (\n",
    "                trajectory_sampled[time_column_name][i + 1]\n",
    "                - trajectory_sampled[time_column_name][i]\n",
    "                == sample_T\n",
    "            ):\n",
    "                # If the difference is 10 minutes, add the current timestamp to the sequence\n",
    "                if len(current_sequence) == 0:\n",
    "                    current_sequence = trajectory_sampled.iloc[\n",
    "                        [i]\n",
    "                    ]  # Add the first timestamp of the sequence\n",
    "                current_sequence = pd.concat(\n",
    "                    [current_sequence, trajectory_sampled.iloc[[i + 1]]],\n",
    "                    ignore_index=True,\n",
    "                )  # Add the next timestamp\n",
    "            else:\n",
    "                # If the difference is not 10 minutes, end the current sequence\n",
    "                if len(current_sequence) != 0:\n",
    "                    trajectory_sequences.append(\n",
    "                        current_sequence\n",
    "                    )  # Store the completed sequence\n",
    "                    current_sequence = pd.DataFrame(\n",
    "                        columns=trajectory_sampled.columns\n",
    "                    )  # Reset the current sequence\n",
    "\n",
    "        # Handle the last sequence if it ends at the last timestamp\n",
    "        if len(current_sequence) != 0:\n",
    "            trajectory_sequences.append(current_sequence)\n",
    "\n",
    "        return trajectory_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a27ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveExtendedKalmanFilter:\n",
    "    def __init__(self, initial_state, initial_covariance, process_noise, measurement_noise, alpha=0.7):\n",
    "        \"\"\"\n",
    "        Initialize the Adaptive Extended Kalman Filter.\n",
    "        \n",
    "        Parameters:\n",
    "        - initial_state: Initial state vector [lat, lon, sog, cog]\n",
    "        - initial_covariance: Initial covariance matrix\n",
    "        - process_noise: Process noise covariance matrix\n",
    "        - measurement_noise: Measurement noise covariance matrix\n",
    "        \"\"\"\n",
    "        self.state = initial_state\n",
    "        self.covariance = initial_covariance\n",
    "        self.Q = process_noise  # Process noise covariance\n",
    "        self.R = measurement_noise  # Measurement noise covariance\n",
    "        self.innovation_history = []\n",
    "        self.window_size = 5  # Window size for adaptive estimation\n",
    "        self.alpha = alpha  # Forgetting factor\n",
    "        \n",
    "    def predict(self, dt):\n",
    "        \"\"\"\n",
    "        Prediction step of the AEKF.\n",
    "        \n",
    "        Parameters:\n",
    "        - dt: Time step in hours (since coordinates are in degrees)\n",
    "        \"\"\"\n",
    "        # State transition matrix (simple constant velocity model)\n",
    "        F = np.eye(4)\n",
    "        F[0, 2] = dt * np.cos(np.radians(self.state[3])) / 60  # latitude change from SOG/COG\n",
    "        F[1, 2] = dt * np.sin(np.radians(self.state[3])) / 60  # longitude change from SOG/COG\n",
    "        \n",
    "        # Predict state\n",
    "        self.state = F @ self.state\n",
    "        \n",
    "        # Predict covariance\n",
    "        self.covariance = F @ self.covariance @ F.T + self.Q\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    def update(self, measurement):\n",
    "        \"\"\"\n",
    "        Update step of the AEKF with adaptive noise estimation.\n",
    "        \n",
    "        Parameters:\n",
    "        - measurement: [lat, lon, sog, cog]\n",
    "        \"\"\"\n",
    "        # Measurement matrix (we directly observe all states)\n",
    "        H = np.eye(4)\n",
    "        \n",
    "        # Calculate innovation\n",
    "        innovation = measurement - H @ self.state\n",
    "        self.innovation_history.append(innovation)\n",
    "        \n",
    "        # Keep only the most recent innovations\n",
    "        if len(self.innovation_history) > self.window_size:\n",
    "            self.innovation_history.pop(0)\n",
    "        \n",
    "        # Adaptive estimation of measurement noise\n",
    "        if len(self.innovation_history) >= 2:\n",
    "            innovation_cov = np.cov(np.array(self.innovation_history).T)\n",
    "            self.R = self.alpha * innovation_cov + (1 - self.alpha) * self.R\n",
    "        \n",
    "        # Kalman gain\n",
    "        S = H @ self.covariance @ H.T + self.R\n",
    "        K = self.covariance @ H.T @ inv(S)\n",
    "        \n",
    "        # Update state\n",
    "        self.state = self.state + K @ innovation\n",
    "        \n",
    "        # Update covariance\n",
    "        self.covariance = (np.eye(4) - K @ H) @ self.covariance\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    def get_state(self):\n",
    "        \"\"\"Return the current state estimate.\"\"\"\n",
    "        return self.state\n",
    "\n",
    "\n",
    "def AEKF_traj(df, alpha = 0.7):\n",
    "    \"\"\"\n",
    "    Apply Adaptive Extended Kalman Filter to the vessel tracking dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame with columns ['Sampled_Date', 'MMSI', 'Latitude', 'Longitude', 'SOG', 'COG', 'Heading']\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with filtered positions and additional AEKF output\n",
    "    \"\"\"\n",
    "    # Sort by MMSI and timestamp\n",
    "    df = df.sort_values(['MMSI', 'Sampled_Date'])\n",
    "    \n",
    "    # Convert datetime to seconds for delta time calculation\n",
    "    df['time_seconds'] = pd.to_datetime(df['Sampled_Date']).astype('int64') // 10**9\n",
    "    \n",
    "    # Initialize output columns\n",
    "    df['filtered_lat'] = np.nan\n",
    "    df['filtered_lon'] = np.nan\n",
    "    df['filtered_sog'] = np.nan\n",
    "    df['filtered_cog'] = np.nan\n",
    "    \n",
    "    # Group by vessel (MMSI)\n",
    "    for mmsi, group in df.groupby('MMSI'):\n",
    "        if len(group) < 2:\n",
    "            continue  # Need at least 2 points for filtering\n",
    "            \n",
    "        # Initialize AEKF with first measurement\n",
    "        initial_state = np.array([\n",
    "            group.iloc[0]['Latitude'],\n",
    "            group.iloc[0]['Longitude'],\n",
    "            group.iloc[0]['SOG'],\n",
    "            group.iloc[0]['COG']\n",
    "        ])\n",
    "        \n",
    "        # Initial covariance (tune these based on your application)\n",
    "        initial_covariance = np.diag([1e-4, 1e-4, 0.1, 1.0])\n",
    "        \n",
    "        # Process noise covariance (tune these)\n",
    "        process_noise = np.diag([1e-6, 1e-6, 0.01, 0.1])\n",
    "        \n",
    "        # Measurement noise covariance (tune these)\n",
    "        measurement_noise = np.diag([1e-5, 1e-5, 0.1, 1.0])\n",
    "        \n",
    "        aekf = AdaptiveExtendedKalmanFilter(\n",
    "            initial_state, initial_covariance, process_noise, measurement_noise, alpha\n",
    "        )\n",
    "        \n",
    "        # Store first filtered values (same as measurement)\n",
    "        # df.loc[group.index[0], 'filtered_lat'] = initial_state[0]\n",
    "        # df.loc[group.index[0], 'filtered_lon'] = initial_state[1]\n",
    "        # df.loc[group.index[0], 'filtered_sog'] = initial_state[2]\n",
    "        # df.loc[group.index[0], 'filtered_cog'] = initial_state[3]\n",
    "        \n",
    "        # Iterate through remaining points\n",
    "        for i in range(1, len(group)):\n",
    "            prev_time = group.iloc[i-1]['time_seconds']\n",
    "            curr_time = group.iloc[i]['time_seconds']\n",
    "            dt = (curr_time - prev_time) / 3600  # hours\n",
    "            \n",
    "            # Prediction step\n",
    "            aekf.predict(dt)\n",
    "            \n",
    "            # Update step with current measurement\n",
    "            measurement = np.array([\n",
    "                group.iloc[i]['Latitude'],\n",
    "                group.iloc[i]['Longitude'],\n",
    "                group.iloc[i]['SOG'],\n",
    "                group.iloc[i]['COG']\n",
    "            ])\n",
    "            \n",
    "            filtered_state = aekf.update(measurement)\n",
    "            \n",
    "            # Store filtered values\n",
    "            df.loc[group.index[i], cols.Latitude] = filtered_state[0]\n",
    "            df.loc[group.index[i], cols.Longitude] = filtered_state[1]\n",
    "            df.loc[group.index[i], cols.SOG] = filtered_state[2]\n",
    "            df.loc[group.index[i], cols.COG] = filtered_state[3]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('your_data.csv')  # Load your data\n",
    "# filtered_df = apply_aekf_to_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b55daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_missing_timestamps(df, freq='10T', interpolation_method='linear', noise_level=0.0):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Make sure the time column is in datetime format\n",
    "    df[cols.Sampled_Date] = pd.to_datetime(df[cols.Sampled_Date])\n",
    "    \n",
    "    # Set the timestamp as index\n",
    "    df = df.set_index(cols.Sampled_Date)\n",
    "\n",
    "    full_range = pd.date_range(\n",
    "        start=df.index.min(),\n",
    "        end=df.index.max(),\n",
    "        freq=freq\n",
    "    )\n",
    "        \n",
    "    # Reindex to the complete time range\n",
    "    df = df.reindex(full_range)\n",
    "        \n",
    "    # Reset index to make Sampled_Date a column again\n",
    "    df = df.reset_index().rename(columns={'index': cols.Sampled_Date})\n",
    "            \n",
    "    # Interpolate numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Store original non-null values to only add noise to interpolated points\n",
    "    original_mask = df[numeric_cols].notna()\n",
    "    \n",
    "    # Perform interpolation\n",
    "    df[numeric_cols] = df[numeric_cols].interpolate(method=interpolation_method)\n",
    "    \n",
    "    # Add noise (either independent or random walk)\n",
    "    if noise_level > 0:\n",
    "        # Apply random walk noise between known points\n",
    "        for col in [cols.Longitude, cols.Latitude]:\n",
    "            # Find where original data exists (anchor points)\n",
    "            anchors = original_mask[col]\n",
    "            anchor_indices = np.where(anchors)[0]\n",
    "            \n",
    "            # Iterate through each segment between anchors\n",
    "            for i in range(len(anchor_indices) - 1):\n",
    "                start_idx = anchor_indices[i]\n",
    "                end_idx = anchor_indices[i + 1]\n",
    "                segment_length = end_idx - start_idx - 1\n",
    "                \n",
    "                if segment_length > 0:\n",
    "                    # Generate random steps (Brownian motion)\n",
    "                    steps = np.random.normal(\n",
    "                        scale=noise_level, \n",
    "                        size=segment_length\n",
    "                    )\n",
    "                    # Accumulate noise (cumulative sum)\n",
    "                    noise = np.cumsum(steps)\n",
    "                    # Apply noise to the interpolated segment\n",
    "                    df.loc[start_idx + 1 : end_idx - 1, col] += noise\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = restore_missing_timestamps(your_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c8d93578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_plotly_trajectory_groups(df_groups: List[List[pd.DataFrame]],\n",
    "                         group_names, \n",
    "                         color_sequence=None,\n",
    "                         line_width=2,\n",
    "                         marker_size=4):\n",
    "    if not df_groups:\n",
    "        raise ValueError(\"Empty list of DataFrame groups provided\")\n",
    "    \n",
    "    if color_sequence is None:\n",
    "        color_sequence = px.colors.qualitative.Plotly\n",
    "    \n",
    "    # Create empty figure with proper mapbox setup\n",
    "    fig = px.scatter_mapbox(lat=[None], lon=[None]).update_layout(\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        mapbox_zoom=8,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    for group_id, df_group in enumerate(df_groups):\n",
    "        group_color = color_sequence[group_id % len(color_sequence)]\n",
    "        \n",
    "        for segment_id, df in enumerate(df_group):\n",
    "            if len(df) == 0:\n",
    "                continue  # Skip empty dataframes\n",
    "                \n",
    "            # Add line trace for this segment\n",
    "            fig.add_trace(\n",
    "                px.line_mapbox(\n",
    "                    df,\n",
    "                    lat=\"Latitude\",\n",
    "                    lon=\"Longitude\",\n",
    "                    color_discrete_sequence=[group_color]\n",
    "                ).data[0].update(\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(width=line_width),\n",
    "                    marker=dict(size=marker_size),\n",
    "                    name=f\"{group_names[group_id]}\",\n",
    "                    showlegend=(segment_id == 0),  # Only show legend for first segment\n",
    "                    legendgroup=f\"{group_names[group_id]}\",\n",
    "                    hoverinfo=\"text\",\n",
    "                    customdata=df[[\"Sampled_Date\", \"SOG\", \"COG\", \"MMSI\"]],\n",
    "                    hovertemplate=(\n",
    "                        \"Latitude: %{lat}<br>\"\n",
    "                        \"Longitude: %{lon}<br>\"\n",
    "                        \"Date: %{customdata[0]}<br>\"\n",
    "                        \"SOG: %{customdata[1]}<br>\"\n",
    "                        \"COG: %{customdata[2]}<br>\"\n",
    "                        \"MMSI: %{customdata[3]}<extra></extra>\"\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0},\n",
    "        showlegend=True,\n",
    "        legend_title_text=\"Trajectory Groups\",\n",
    "        title=\"Vessel Trajectory\"\n",
    "    )\n",
    "    \n",
    "    # Auto-zoom to the data\n",
    "    if len(df_groups) > 0 and len(df_groups[0]) > 0:\n",
    "        first_df = df_groups[0][0]\n",
    "        fig.update_mapboxes(\n",
    "            center=dict(\n",
    "                lat=first_df[\"Latitude\"].mean(),\n",
    "                lon=first_df[\"Longitude\"].mean()\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92a3eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_boats_trajectories_list = list(all_boats_trajectories.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8822244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 0.0%\n",
      "1, 0.15082956259426847%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 0.30165912518853694%\n",
      "3, 0.45248868778280543%\n",
      "4, 0.6033182503770739%\n",
      "5, 0.7541478129713424%\n",
      "6, 0.9049773755656109%\n",
      "7, 1.0558069381598794%\n",
      "8, 1.2066365007541477%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9, 1.3574660633484164%\n",
      "10, 1.5082956259426847%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11, 1.6591251885369533%\n",
      "12, 1.8099547511312217%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13, 1.9607843137254901%\n",
      "14, 2.1116138763197587%\n",
      "15, 2.262443438914027%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16, 2.4132730015082955%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17, 2.5641025641025643%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18, 2.7149321266968327%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19, 2.865761689291101%\n",
      "20, 3.0165912518853695%\n",
      "21, 3.167420814479638%\n",
      "22, 3.3182503770739067%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23, 3.469079939668175%\n",
      "24, 3.6199095022624435%\n",
      "25, 3.770739064856712%\n",
      "26, 3.9215686274509802%\n",
      "27, 4.072398190045249%\n",
      "28, 4.223227752639517%\n",
      "29, 4.374057315233785%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30, 4.524886877828054%\n",
      "31, 4.675716440422323%\n",
      "32, 4.826546003016591%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n",
      "/var/folders/xl/2j0v3vnj3gbfd5vvjwwz9lr00000gn/T/ipykernel_5160/727958986.py:10: FutureWarning:\n",
      "\n",
      "'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, traj in enumerate(all_boats_trajectories_list):\n",
    "    print(f\"{i}, {100.0*i/len(all_boats_trajectories_list)}%\")\n",
    "    sample_traj = get_sampled_trajectory(traj)\n",
    "    if len(sample_traj) < 40 or len(sample_traj) > 100:\n",
    "        continue\n",
    "    sample_traj_sequences = get_trajectory_sequences(sample_traj)\n",
    "    \n",
    "    png = True\n",
    "    for alpha in [0.2, 0.5, 0.8, 1.0]:\n",
    "        # AEKF_sample_traj = AEKF_traj(sample_traj, alpha)\n",
    "        # AEKF_sample_traj_sequences = get_trajectory_sequences(AEKF_sample_traj)\n",
    "\n",
    "        ### STABLE DIFFUSION\n",
    "        interpolated_sample_traj = restore_missing_timestamps(sample_traj, noise_level=0.0012)\n",
    "        interpolated_sample_traj_sequences = get_trajectory_sequences(interpolated_sample_traj)\n",
    "        AEKF_interpolated_sample_traj= AEKF_traj(interpolated_sample_traj, alpha)\n",
    "        AEKF_interpolated_sample_traj_sequences = get_trajectory_sequences(AEKF_interpolated_sample_traj)\n",
    "\n",
    "\n",
    "        fig = plot_plotly_trajectory_groups([AEKF_interpolated_sample_traj_sequences, sample_traj_sequences], group_names=[\"Stable Diffusion + AEKF\", \"Initial trajectory\"])\n",
    "        fig.write_image(f\"results/png_{i}_sd_traj_alpha_{alpha}.png\")\n",
    "        fig.write_html(f\"results/html_{i}_sd_traj_alpha_{alpha}.html\")\n",
    "        \n",
    "        ### JUST AEKF\n",
    "        interpolated_sample_traj = restore_missing_timestamps(sample_traj, noise_level=0.0000)\n",
    "        interpolated_sample_traj_sequences = get_trajectory_sequences(interpolated_sample_traj)\n",
    "        AEKF_interpolated_sample_traj= AEKF_traj(interpolated_sample_traj, alpha)\n",
    "        AEKF_interpolated_sample_traj_sequences = get_trajectory_sequences(AEKF_interpolated_sample_traj)\n",
    "\n",
    "        fig = plot_plotly_trajectory_groups([AEKF_interpolated_sample_traj_sequences, sample_traj_sequences], group_names=[\"Interpolated + AEKF\", \"Initial trajectory\"])\n",
    "        fig.write_image(f\"results/png_{i}_interpolated_traj_alpha_{alpha}.png\")\n",
    "        fig.write_html(f\"results/html_{i}_interpolated_traj_alpha_{alpha}.html\")\n",
    "    # break\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d27b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_traj_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_folium_trajectory(dfs: List[pd.DataFrame]):    \n",
    "#     # Create map centered on first point\n",
    "#     m = folium.Map(location=[dfs[0].iloc[0]['Latitude'], dfs[0].iloc[0]['Longitude']], zoom_start=10)\n",
    "\n",
    "#     for vessel_df in dfs:\n",
    "#         # Add points with popup info\n",
    "#         for idx, row in vessel_df.iterrows():\n",
    "#             popup = f\"MMSI: {row['MMSI']}<br>Time: {row['Sampled_Date']}<br>SOG: {row['SOG']} kn<br>COG: {row['COG']}Â°\"\n",
    "#             folium.CircleMarker(\n",
    "#                 location=[row['Latitude'], row['Longitude']],\n",
    "#                 radius=3,\n",
    "#                 popup=popup,\n",
    "#                 color='blue',\n",
    "#                 fill=True\n",
    "#             ).add_to(m)\n",
    "        \n",
    "#         # Add line connecting points\n",
    "#         folium.PolyLine(\n",
    "#             locations=vessel_df[['Latitude', 'Longitude']].values,\n",
    "#             color='green',\n",
    "#             weight=2,\n",
    "#             opacity=0.7\n",
    "#         ).add_to(m)\n",
    "    \n",
    "#     return m\n",
    "\n",
    "# Example usage:\n",
    "# plot_folium_trajectory(your_df, 123456789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04ee3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_folium_trajectory(sample_traj_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_plotly_trajectory(dfs: List[pd.DataFrame], \n",
    "#                                    color_sequence=None,\n",
    "#                                    line_width=2,\n",
    "#                                    marker_size=4):\n",
    "#     if not dfs:\n",
    "#         raise ValueError(\"Empty list of DataFrames provided\")\n",
    "    \n",
    "#     # Combine all segments with a segment ID\n",
    "#     combined_df = pd.concat(\n",
    "#         [df.assign(segment_id=i) for i, df in enumerate(dfs)],\n",
    "#         ignore_index=True\n",
    "#     )\n",
    "    \n",
    "#     if color_sequence is None:\n",
    "#         color_sequence = px.colors.qualitative.Plotly\n",
    "    \n",
    "#     fig = px.line_mapbox(\n",
    "#         combined_df,\n",
    "#         lat=\"Latitude\",\n",
    "#         lon=\"Longitude\",\n",
    "#         color=\"segment_id\",\n",
    "#         color_discrete_sequence=[\"blue\"],\n",
    "#         hover_name=\"Sampled_Date\",\n",
    "#         hover_data=[\"SOG\", \"COG\", \"MMSI\"],\n",
    "#         zoom=10,\n",
    "#         height=600,\n",
    "#         title=\"Vessel Trajectory Segments\"\n",
    "#     )\n",
    "    \n",
    "#     # Update marker appearance\n",
    "#     fig.update_traces(\n",
    "#         mode=\"lines+markers\",\n",
    "#         line=dict(width=line_width),\n",
    "#         marker=dict(size=marker_size)\n",
    "#     )\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         mapbox_style=\"carto-positron\",\n",
    "#         margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0},\n",
    "#         showlegend=False,\n",
    "#         legend_title_text=\"Trajectory Segment\"\n",
    "#     )\n",
    "    \n",
    "#     return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a98f43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_plotly_trajectory(sample_traj_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1919b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_cartopy_trajectory_segments(dfs: List[pd.DataFrame]):\n",
    "#     if not dfs:\n",
    "#         raise ValueError(\"Empty list of DataFrames provided\")\n",
    "    \n",
    "#     # Set default colors if not provided\n",
    "#     colors = [\"blue\"]*len(dfs)\n",
    "    \n",
    "#     # Create figure\n",
    "#     fig = plt.figure(figsize=(12, 8))\n",
    "#     ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    \n",
    "#     # Add map features\n",
    "#     ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "#     ax.add_feature(cfeature.OCEAN, facecolor='lightblue')\n",
    "#     ax.add_feature(cfeature.COASTLINE, edgecolor='black')\n",
    "#     ax.add_feature(cfeature.BORDERS, linestyle=':', edgecolor='gray')\n",
    "    \n",
    "#     # Plot each segment\n",
    "#     for i, df in enumerate(dfs):\n",
    "#         # Handle line width and marker size (single value or list)\n",
    "#         lw = 2\n",
    "#         ms = 4\n",
    "        \n",
    "#         ax.plot(\n",
    "#             df['Longitude'],\n",
    "#             df['Latitude'],\n",
    "#             color=colors[i],\n",
    "#             linewidth=lw,\n",
    "#             marker='o',\n",
    "#             markersize=ms,\n",
    "#             transform=ccrs.PlateCarree(),\n",
    "#             label=f'Segment {i+1}'\n",
    "#         )\n",
    "        \n",
    "#         # Mark start and end points\n",
    "#         ax.plot(\n",
    "#             df['Longitude'].iloc[0],\n",
    "#             df['Latitude'].iloc[0],\n",
    "#             'o',\n",
    "#             color=colors[i],\n",
    "#             markersize=ms+2,\n",
    "#             transform=ccrs.PlateCarree()\n",
    "#         )\n",
    "#         ax.plot(\n",
    "#             df['Longitude'].iloc[-1],\n",
    "#             df['Latitude'].iloc[-1],\n",
    "#             's',\n",
    "#             color=colors[i],\n",
    "#             markersize=ms+2,\n",
    "#             transform=ccrs.PlateCarree()\n",
    "#         )\n",
    "    \n",
    "#     # Add legend and title\n",
    "#     # ax.legend(loc='upper right')\n",
    "#     plt.title('Vessel Trajectory Segments')\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20bdb69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_cartopy_trajectory_segments(sample_traj_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def plot_pydeck_trajectory_segments(dfs: List[pd.DataFrame]):\n",
    "#     if not dfs:\n",
    "#         raise ValueError(\"Empty list of DataFrames provided\")\n",
    "    \n",
    "#     # Combine all segments with segment IDs\n",
    "#     combined_df = pd.concat(\n",
    "#         [df.assign(segment_id=i) for i, df in enumerate(dfs)],\n",
    "#         ignore_index=True\n",
    "#     )\n",
    "    \n",
    "#     # Default colors if not provided\n",
    "#     # colors = [\"blue\"]*len(dfs)\n",
    "    \n",
    "#     # Create a view centered on the first point\n",
    "#     view_state = pdk.ViewState(\n",
    "#         latitude=dfs[0].iloc[0]['Latitude'],\n",
    "#         longitude=dfs[0].iloc[0]['Longitude'],\n",
    "#         zoom=10\n",
    "#     )\n",
    "    \n",
    "#     # Create line layer\n",
    "#     line_layer = pdk.Layer(\n",
    "#         \"PathLayer\",\n",
    "#         data=combined_df.groupby('segment_id')\n",
    "#             .apply(lambda x: x[['Longitude', 'Latitude']].values.tolist())\n",
    "#             .reset_index()\n",
    "#             .rename(columns={0: 'path'}),\n",
    "#         get_path='path',\n",
    "#         get_color='[50, 200, 150]',\n",
    "#         get_width=100,\n",
    "#         pickable=True\n",
    "#     )\n",
    "    \n",
    "#     # Create scatter plot layer for points\n",
    "#     scatter_layer = pdk.Layer(\n",
    "#         \"ScatterplotLayer\",\n",
    "#         data=combined_df,\n",
    "#         get_position=['Longitude', 'Latitude'],\n",
    "#         get_color='[0, 0, 0, 160]',\n",
    "#         get_radius=100,\n",
    "#         pickable=True\n",
    "#     )\n",
    "    \n",
    "#     # Create tooltip\n",
    "#     tooltip = {\n",
    "#         \"html\": \"<b>MMSI:</b> {MMSI}<br/>\"\n",
    "#                 \"<b>Time:</b> {Sampled_Date}<br/>\"\n",
    "#                 \"<b>SOG:</b> {SOG} kn<br/>\"\n",
    "#                 \"<b>COG:</b> {COG}Â°\",\n",
    "#         \"style\": {\n",
    "#             \"backgroundColor\": \"white\",\n",
    "#             \"color\": \"black\"\n",
    "#         }\n",
    "#     }\n",
    "    \n",
    "#     # Render\n",
    "#     r = pdk.Deck(\n",
    "#         layers=[line_layer, scatter_layer],\n",
    "#         initial_view_state=view_state,\n",
    "#         tooltip=tooltip\n",
    "#     )\n",
    "    \n",
    "#     return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c038f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_pydeck_trajectory_segments(sample_traj_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1407863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ssa(eps):\n",
    "#     \"\"\"\n",
    "#     Convert latitude and longitude residuals to the standard range of -pi to pi.\n",
    "    \n",
    "#     Args:\n",
    "#         eps (np.array): Residuals.\n",
    "        \n",
    "#     Returns:\n",
    "#         np.array: Standardized residuals.\n",
    "#     \"\"\"\n",
    "#     # Normalize latitude to the range [-pi/2, pi/2]\n",
    "#     eps[0] = (eps[0] + np.pi/2) % (np.pi) - np.pi/2\n",
    "#     # Normalize longitude to the range [-pi, pi]\n",
    "#     eps[1] = (eps[1] + np.pi) % (2 * np.pi) - np.pi\n",
    "#     return eps\n",
    "\n",
    "# def AEKF_traj(traj: pd.DataFrame, alpha: float = 0.2):\n",
    "#     \"\"\"\n",
    "#     Compute a trajectory correction using an adaptive Extened Kalman filter for maritime vessel data.\n",
    "#     If alpha = 0: Extended Kalman Filter\n",
    "    \n",
    "#     Args:\n",
    "#         traj pd.DataFrame: The input trajectory data.\n",
    "#         alpha (float): Weighting factor for process and measurement noise adjustments.\n",
    "    \n",
    "#     Returns:\n",
    "#         mpd.Trajectory: Corrected trajectory.\n",
    "#     \"\"\"\n",
    "#     target_vessel = traj.copy()  # Extract trajectory data as a DataFrame\n",
    "#     mmsi = int(target_vessel[\"MMSI\"].unique()[0])  # Extract unique vessel identifier (MMSI)\n",
    "#     a = 6378137  # Semi-major axis (equatorial radius) in meters\n",
    "#     f = 1 / 298.257223563  # Flattening factor of Earth\n",
    "#     e = np.sqrt(2 * f - f**2)  # Earth eccentricity\n",
    "#     alpha_1 = 0.01  # Damping coefficient for speed\n",
    "#     alpha_2 = 0.01  # Damping coefficient for angular velocity\n",
    "\n",
    "#     # Convert latitude and longitude to radians\n",
    "#     lat = np.deg2rad(target_vessel[cols.Latitude].values).tolist()\n",
    "#     lon = np.deg2rad(target_vessel[cols.Longitude].values).tolist()\n",
    "\n",
    "#     # Initial process and measurement noise covariance matrices\n",
    "#     Q11 = 1e8\n",
    "#     Q22 = 1e2\n",
    "#     R11 = R22 = 36\n",
    "#     Qd = np.diag([Q11, Q22])  # Process noise covariance\n",
    "#     Rd = np.diag([R11, R22])  # Measurement noise covariance\n",
    "\n",
    "#     frame = 'LL'  # Coordinate frame ('LL' for Latitude/Longitude)\n",
    "#     P_prd = np.eye(5)  # Initial prediction covariance matrix\n",
    "#     I5 = np.eye(5)  # 5x5 Identity matrix\n",
    "#     Cd = np.array([[1, 0, 0, 0, 0],  # Observation matrix for position\n",
    "#                    [0, 1, 0, 0, 0]])\n",
    "#     coord_ls = []  # List to store corrected positions\n",
    "#     sog = []  # List to store corrected speed over ground\n",
    "#     cog = []  # List to store corrected course over ground\n",
    "\n",
    "#     # Initialize state vector (latitude, longitude, speed, angle, angular velocity)\n",
    "#     x_hat = np.array([lat[0], lon[0], 0, 0, 0], dtype=float)\n",
    "\n",
    "#     # Calculate time steps in seconds\n",
    "#     dt_ = np.diff(target_vessel.index.view(int) // 1e9)\n",
    "#     dt_min = dt_.min()  # Minimum time step\n",
    "#     dts = np.hstack([0, dt_])  # Append 0 for initial time step\n",
    "    \n",
    "#     delta_q = 0\n",
    "#     delta_r = 0\n",
    "#     try:\n",
    "\n",
    "#         for i in range(len(lat)):  # Main loop over all data points\n",
    "#             h_samp = dts[i]  # Sampling interval for the current step\n",
    "\n",
    "#             # Adjust process and measurement noise adaptively based on sampling interval\n",
    "#             if alpha != 0:\n",
    "#                 if h_samp != 0:\n",
    "#                     Qd = (alpha) * (h_samp / dt_min) * np.diag([Q11, Q22]) + (1 - alpha) * delta_q\n",
    "#                     Rd = (alpha) * (dt_min / h_samp) * np.diag([R11, R22]) + (1 - alpha) * delta_r\n",
    "            \n",
    "#             # GNSS measurement for current step\n",
    "#             mu = lat[i]\n",
    "#             l = lon[i]\n",
    "#             y = np.array([mu, l])  # Observation vector\n",
    "\n",
    "#             # Sampling matrix\n",
    "#             Ed = h_samp * np.array([[0, 0],\n",
    "#                                     [0, 0],\n",
    "#                                     [1, 0],\n",
    "#                                     [0, 0],\n",
    "#                                     [0, 1]])\n",
    "            \n",
    "#             # Calculate Earth radius values for the current latitude\n",
    "#             Rn = a / np.sqrt(1 - e**2 * np.sin(x_hat[0])**2)  # Radius of curvature in the prime vertical\n",
    "#             Rm = Rn * ((1 - e**2) / (1 - e**2 * np.sin(x_hat[0])**2))  # Radius of curvature in the meridian\n",
    "\n",
    "#             # State transition function\n",
    "#             f = np.array([(1 / Rm) * x_hat[2] * np.cos(x_hat[3]),  # Latitude rate\n",
    "#                         (1 / (Rn * np.cos(x_hat[0]))) * x_hat[2] * np.sin(x_hat[3]),  # Longitude rate\n",
    "#                         -alpha_1 * x_hat[2],  # Speed damping\n",
    "#                         x_hat[4],  # Angle rate\n",
    "#                         -alpha_2 * x_hat[4]])  # Angular velocity damping\n",
    "\n",
    "#             # State transition matrix\n",
    "#             A21 = (x_hat[2] * np.sin(x_hat[3]) * np.tan(x_hat[0])) / (Rn * np.cos(x_hat[0]))\n",
    "#             Ad = I5 + h_samp * np.array([\n",
    "#                 [0, 0, (1 / Rm) * np.cos(x_hat[3]), -(1 / Rm) * x_hat[2] * np.sin(x_hat[3]), 0],\n",
    "#                 [A21, 0, (1 / (Rn * np.cos(x_hat[0]))) * np.sin(x_hat[3]), (1 / (Rn * np.cos(x_hat[0]))) * x_hat[2] * np.cos(x_hat[3]), 0],\n",
    "#                 [0, 0, -alpha_1, 0, 0],\n",
    "#                 [0, 0, 0, 0, 1],\n",
    "#                 [0, 0, 0, 0, -alpha_2]])\n",
    "\n",
    "#             # Predict state and covariance\n",
    "#             x_prd = x_hat + h_samp * f\n",
    "#             P_hat = Ad @ P_prd @ Ad.T + Ed @ Qd @ Ed.T\n",
    "\n",
    "#             # Compute observation residual\n",
    "#             d = y - Cd @ x_prd\n",
    "#             if frame == 'LL':  # Normalize residuals if in latitude/longitude frame\n",
    "#                 d = ssa(d)\n",
    "\n",
    "#             # Compute Kalman gain\n",
    "#             S = Cd @ P_hat @ Cd.T + Rd\n",
    "#             K = P_hat @ Cd.T @ np.linalg.inv(S)\n",
    "#             IKC = I5 - K @ Cd  # Update factor for covariance matrix\n",
    "\n",
    "#             # Update state and covariance\n",
    "#             P_prd = IKC @ P_hat @ IKC.T + K @ Rd @ K.T\n",
    "#             x_hat = x_prd + K @ d\n",
    "#             x_hat[:2] = ssa(x_hat[:2])  # Normalize latitude and longitude\n",
    "\n",
    "#             # Update process noise covariance (adaptive filtering)\n",
    "#             delta_q = (Cd @ K @ np.expand_dims(d, 1) @ np.expand_dims(d, 1).T @ K.T @ Cd.T) * np.eye(2) % 1e8\n",
    "            \n",
    "#             esp = y - Cd @ x_hat\n",
    "#             esp = np.expand_dims(esp, 1)\n",
    "#             delta_r = (esp @ esp.T + Cd @ P_hat @ Cd.T) *np.eye(2) / R11\n",
    "#             # Store corrected state values\n",
    "#             coord_ls.append(np.rad2deg(x_hat[:2]))  # Convert latitude/longitude back to degrees\n",
    "#             sog.append(x_hat[2] / 0.51444444)  # Convert speed to knots\n",
    "#             cog.append(np.rad2deg(x_hat[3]) % 360)  # Normalize angle to [0, 360]\n",
    "#             # print(sog)\n",
    "            \n",
    "\n",
    "#         # Create corrected trajectory DataFrame\n",
    "#         states = [i.tolist() for i in coord_ls]\n",
    "#         lat, lon = list(zip(*states))\n",
    "#         traj = pd.DataFrame({cols.Sampled_Date: target_vessel[cols.Sampled_Date], \"MMSI\": [mmsi]*len(lat), cols.Latitude: lat, cols.Longitude: lon, cols.SOG: sog, cols.COG: cog}, index=target_vessel.index)\n",
    "#         # df_geo = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat), crs=CRS_METRIC)\n",
    "#         # traj = mpd.Trajectory(df_geo, traj_id=mmsi)\n",
    "#         return traj\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         return False\n",
    "\n",
    "# def RMSE_error(collection, new_collections_aekf, mask_traj):\n",
    "#     \"\"\"\n",
    "#     Calculate the Root Mean Square Error (RMSE) between true and estimated (filtered) trajectories.\n",
    "\n",
    "#     Args:\n",
    "#         collection (list): A list of true trajectories, each containing latitude and longitude data.\n",
    "#         new_collections_aekf (list): A list of estimated (filtered) trajectories, each containing latitude and longitude data.\n",
    "#         mask_traj (list): A boolean mask list indicating which trajectories should be considered for RMSE calculation.\n",
    "\n",
    "#     Returns:\n",
    "#         list: A list of RMSE values for each pair of true and estimated trajectories.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Initialize an empty list to store RMSE values for each trajectory pair\n",
    "#     RMSE_aekf = list()\n",
    "\n",
    "#     # Filter the collection of true trajectories based on the mask_traj list (only keep True values)\n",
    "#     collection = [collection[idx] for idx in range(len(mask_traj)) if mask_traj[idx] == True]\n",
    "\n",
    "#     # Iterate over pairs of true and estimated trajectories\n",
    "#     for true_traj, est_traj in tqdm(zip(collection, new_collections_aekf), desc=\"RMSE\"):\n",
    "        \n",
    "#         # Extract the latitude and longitude values for the true trajectory and convert to radians\n",
    "#         true_coord = true_traj.df[['lat', 'lon']].values\n",
    "#         true_coord = np.deg2rad(true_coord)  # Convert coordinates to radians for distance calculation\n",
    "        \n",
    "#         # Extract the latitude and longitude values for the estimated trajectory and convert to radians\n",
    "#         pred_coord = est_traj.df[['lat', 'lon']].values\n",
    "#         pred_coord = np.deg2rad(pred_coord)  # Convert coordinates to radians\n",
    "        \n",
    "#         # Compute the Haversine distance between the true and predicted coordinates (distance in km)\n",
    "#         traj_dist = (haversine_distances(true_coord, pred_coord) * 6371) * np.eye(len(true_traj.df))\n",
    "        \n",
    "#         # Remove zero distances (indicating identical points)\n",
    "#         traj_dist = traj_dist[traj_dist != 0]\n",
    "\n",
    "#         # Calculate the Root Mean Square Error (RMSE) as the square root of the mean of squared distances\n",
    "#         rmse = np.sqrt((traj_dist**2).mean())\n",
    "        \n",
    "#         # Append the computed RMSE to the list of RMSE values\n",
    "#         RMSE_aekf.append(rmse)\n",
    "\n",
    "#     return RMSE_aekf  # Return the list of RMSE values for each trajectory pair\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b145b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa58b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AEKF_sample_traj = AEKF_traj(sample_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c52187f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AEKF_sample_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43803d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AEKF_sample_traj_sequences = get_trajectory_sequences(AEKF_sample_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1926651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_folium_trajectory(sample_traj_sequences)\n",
    "# plot_plotly_trajectory(sample_traj_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab0b125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_folium_trajectory(AEKF_sample_traj_sequences)\n",
    "# plot_plotly_trajectory(AEKF_sample_traj_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94490ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47afe8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolated_sample_traj = restore_missing_timestamps(sample_traj, noise_level=0.0007)\n",
    "# interpolated_sample_traj_sequences = get_trajectory_sequences(interpolated_sample_traj)\n",
    "# plot_plotly_trajectory(interpolated_sample_traj_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec904d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AEKF_interpolated_sample_traj= AEKF_traj(interpolated_sample_traj)\n",
    "# AEKF_interpolated_sample_traj_sequences = get_trajectory_sequences(AEKF_interpolated_sample_traj)\n",
    "# plot_plotly_trajectory(AEKF_interpolated_sample_traj_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6717840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ab21ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_plotly_trajectory_groups([AEKF_interpolated_sample_traj_sequences, sample_traj_sequences], group_names=[\"Stable Diffusion + AEKF\", \"Initial trajectory\"])\n",
    "# fig.show()\n",
    "# fig.write_html(\"test_1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177320a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
